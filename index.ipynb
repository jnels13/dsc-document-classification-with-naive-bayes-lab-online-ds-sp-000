{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification with Naive Bayes - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lesson, you'll practice implementing the Naive Bayes algorithm on your own.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab you will:  \n",
    "\n",
    "* Implement document classification using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset\n",
    "\n",
    "To start, import the dataset stored in the text file `'SMSSpamCollection'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('SMSSpamCollection', sep='\\t', names=['label', 'text'])\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Account for class imbalance\n",
    "\n",
    "To help your algorithm perform more accurately, subset the dataset so that the two classes are of equal size. To do this, keep all of the instances of the minority class (spam) and subset examples of the majority class (ham) to an equal number of examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "minority = df[df['label'] == 'spam']\n",
    "majority = df[df['label'] == 'ham']\n",
    "adj_maj = majority.sample(n=len(minority), random_state = 10)\n",
    "df2 = pd.concat([minority, adj_maj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_classes = dict(df2['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split\n",
    "\n",
    "Now implement a train-test split on the dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = pd.concat([minority.text, adj_maj.text])\n",
    "y = pd.concat([minority.label, adj_maj.label])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 12)\n",
    "train_df = pd.concat([X_train, y_train], axis = 1)\n",
    "test_df = pd.concat([X_test, y_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>Claim a 200 shopping spree, just call 08717895...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2827</td>\n",
       "      <td>Ok lor...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4222</td>\n",
       "      <td>Plz note: if anyone calling from a mobile Co. ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4834</td>\n",
       "      <td>New Mobiles from 2004, MUST GO! Txt: NOKIA to ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4778</td>\n",
       "      <td>Sorry completely forgot * will pop em round th...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3017</td>\n",
       "      <td>&amp;lt;#&amp;gt;  is fast approaching. So, Wish u a v...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5004</td>\n",
       "      <td>CDs 4u: Congratulations ur awarded £500 of CD ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3807</td>\n",
       "      <td>URGENT! We are trying to contact you. Last wee...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3506</td>\n",
       "      <td>life alle mone,eppolum oru pole allalo</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1594</td>\n",
       "      <td>PRIVATE! Your 2003 Account Statement for shows...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label\n",
       "3780  Claim a 200 shopping spree, just call 08717895...  spam\n",
       "2827                                          Ok lor...   ham\n",
       "4222  Plz note: if anyone calling from a mobile Co. ...   ham\n",
       "4834  New Mobiles from 2004, MUST GO! Txt: NOKIA to ...  spam\n",
       "4778  Sorry completely forgot * will pop em round th...   ham\n",
       "...                                                 ...   ...\n",
       "3017  &lt;#&gt;  is fast approaching. So, Wish u a v...   ham\n",
       "5004  CDs 4u: Congratulations ur awarded £500 of CD ...  spam\n",
       "3807  URGENT! We are trying to contact you. Last wee...  spam\n",
       "3506             life alle mone,eppolum oru pole allalo   ham\n",
       "1594  PRIVATE! Your 2003 Account Statement for shows...  spam\n",
       "\n",
       "[449 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the word frequency dictionary for each class\n",
    "\n",
    "Create a word frequency dictionary for each class: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "class_m : {}\n",
    "class_word_freq = {} \n",
    "classes = train_df['label'].unique()\n",
    "for class_ in classes:\n",
    "    temp_df = train_df[train_df.label == class_]\n",
    "    bag = {}\n",
    "    for row in temp_df.index:\n",
    "        doc = temp_df['text'][row]\n",
    "        for word in doc.split():\n",
    "            bag[word] = bag.get(word, 0) + 1\n",
    "    class_word_freq[class_] = bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the total corpus words\n",
    "Calculate V, the total number of words in the corpus: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "vocabulary = set()\n",
    "for text in train_df['text']:\n",
    "    for word in text.split():\n",
    "        vocabulary.add(word)\n",
    "V = len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a bag of words function\n",
    "\n",
    "Before implementing the entire Naive Bayes algorithm, create a helper function `bag_it()` to create a bag of words representation from a document's text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def bag_it(doc):\n",
    "    bag = {}\n",
    "    for word in doc.split():\n",
    "        bag[word] = bag.get(word, 0) + 1\n",
    "    return bag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Naive Bayes\n",
    "\n",
    "Now, implement a master function to build a naive Bayes classifier. Be sure to use the logarithmic probabilities to avoid underflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "def classify_doc(doc, class_word_freq, p_classes, V, return_posteriors=False):\n",
    "    bag = bag_it(doc)\n",
    "    classes = []\n",
    "    posteriors = []\n",
    "    for class_ in class_word_freq.keys():\n",
    "        p = p_classes[class_]\n",
    "        for word in bag.keys():\n",
    "            numerator = bag[word]+1\n",
    "            denominator = class_word_freq[class_].get(word, 0) + V\n",
    "            p *= (numerator/denominator)\n",
    "        classes.append(class_)\n",
    "        posteriors.append(p)\n",
    "    if return_posteriors:\n",
    "        print(posteriors)\n",
    "    return classes[np.argmax(posteriors)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your classifier\n",
    "\n",
    "Finally, test your classifier and measure its accuracy. Don't be perturbed if your results are sub-par; industry use cases would require substantial additional preprocessing before implementing the algorithm in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    0.719617\n",
       "True     0.280383\n",
       "dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "y_hat_train = X_train.map(lambda x: classify_doc(x, class_word_freq, p_classes, V))\n",
    "residuals = y_train == y_hat_train\n",
    "residuals.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up (Optional)\n",
    "\n",
    "Rework your code into an appropriate class structure so that you could easily implement the algorithm on any given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Well done! In this lab, you practiced implementing Naive Bayes for document classification!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
